# RCA: Snapshot Not Released After Container Deletion

## Summary

We observed that some containers, after being stopped or deleted, left their snapshots uncollected in the system. This led to unexpected growth in storage usage under containerd-managed directories. GC (Garbage Collection) did not reclaim these snapshots as expected.

---

## Observed Symptoms

- Snapshot directories remained under `/var/lib/containerd/...` after container stopped.
- `ctr snapshots ls` showed references not released.
- Disk usage increased even with no running containers.

---

## Diagnosis Path

### 1. File System Layer
- Check for mount points or open handles via `lsof`.
- Look under overlay mounts or snapshot directories for residual files.

### 2. Metadata Layer
- Use containerd tools (`ctr`, `crictl`) to query snapshots and leases.
- Verify if leases are still active for deleted containers.

### 3. System Call & Recovery Check
- Review `dmesg`, containerd logs for syscall failure, shim crash, or improper teardown.
- Check GC recovery/reconciliation path post-daemon restart.

---

## Key Code Paths & Instrumentation Points

### A. Container Deletion Logic
- `pkg/cri/server/container_remove.go` â `RemoveContainer()`
- `pkg/cri/server/container_stop.go` â `StopContainer()`
- `runtime/v2/shim.go` â `Shutdown()`
- `snapshots/service.go` â `Remove()`

> Instrument around `RemoveContainer` and `task.Delete` to track snapshot lifecycle.

---

### B. Lease Management
- `leases/service.go`:
    - `Create()` â new lease created.
    - `AddResource()` â bind snapshot/blob to lease.
    - `Delete()` â unbind resource for GC eligibility.

> Add logging around `AddResource` to monitor binding.

---

### C. Snapshot Refcount & GC Path
- `metadata/snapshot/storage.go` â `Remove()`, `Usage()`
- `gc/gc.go`:
    - `Run()` â entry point for GC
    - `findUnused()` â collect unreferenced snapshots
    - `deleteUnused()` â remove snapshots

> Add log to track refcount behavior during snapshot mutation.

---

## Likely Root Causes

- Lease still active or not properly deleted.
- Refcount never reached 0 due to zombie processes or missed metadata update.
- GC skipped snapshot due to inconsistent metadata.

---

## Recommendations

1. Add logs at:
    - `RemoveContainer()`
    - `snapshot.Remove()`
    - `lease.Delete()` and `AddResource()`
2. Monitor GC run output.
3. Use metrics like:
    - `gc.snapshot.orphan.count`
    - `snapshot.lease.bind.count`
4. Consider forced unbind of zombie leases during GC for safety fallback.

---







你的回答已经非常全面且结构合理，涵盖了系统设计中最核心的三块：
	•	热点识别与冷热分层策略（S3 vs Glacier）
	•	GC 风险控制与元数据驱动的精确回收
	•	使用事务性存储确保元数据一致性（提到 Redis，略可再斟酌）

现在我来为你润色并结构化整理成一个可以在系统设计面试中直接使用的答案版本：

⸻

Refined Answer: Blob Lifecycle Optimization for Cost and Safety

1. Hot vs Cold Blob Classification

In our current image registry system, each image consists of multiple layered blobs. We’ve observed that over 200TB of storage is consumed monthly, yet only 5% of blobs are accessed within any 30-day window.

To classify blobs as hot or cold, we propose:
	•	Tracking last accessed timestamps using metrics or a sidecar trace/logging layer.
	•	Defining “hot” blobs as those accessed within 7 or 30 days.
	•	Marking “cold” blobs as those unused beyond that threshold.

⸻

2. S3 Storage Tiering Strategy

To reduce cost, we utilize AWS S3’s lifecycle management:
	•	S3 Standard for hot blobs (frequently accessed).
	•	S3 Standard-IA (Infrequent Access) for mid-use blobs.
	•	S3 Glacier or Glacier Deep Archive for long-tail cold blobs, which are rarely accessed but must be preserved.

We configure a lifecycle policy to:
	•	Transition blobs to S3-IA after 30 days of inactivity;
	•	Move blobs to Glacier after 90 days;
	•	Optionally delete after 1 year if refcount is zero and lease is expired.

This multi-tier model allows us to balance performance and cost while preserving recovery capability.

⸻

3. Safe GC Design Using Metadata and Reference Counting

To safely collect unused blobs, we design GC as metadata-driven rather than access-event-driven.
	•	Each blob and snapshot is tracked in a metadata store using:
	•	Lease association (to track logical ownership);
	•	Reference count (to track dependency and reachability).
	•	GC runs only if:
	•	refcount == 0
	•	no active lease
	•	metadata confirms no descendant references

To ensure metadata consistency, we recommend storing it in a transactional key-value store like BoltDB (as used by containerd) or another embedded DB with crash recovery.

This ensures GC decisions are deterministic, auditable, and resilient to crash recovery or concurrent write conflicts.

⸻

Summary

By decoupling blob access frequency from lifecycle control, and enforcing GC via metadata truth rather than events, we build a cost-efficient, safe, and robust image storage system suitable for long-term scale and audit requirements.

⸻

是否需要我将这段输出整理为一份 Markdown 格式的“系统设计 + 成本推理答题模板”？你未来可用于项目设计写作或面试评审材料中。你说我就生成。






你写的表达已经很完整，成功解释了 containerd 的 GC 机制：
	•	元数据驱动（metadata-driven）而非事件触发（event-driven）
	•	通过 lease 和 refcount 确保不会误删
	•	强调 crash recovery 和并发下的安全保障

我来为你润色优化，使它更具“系统设计讨论”风格，语句更清晰流畅，并添加一些常用术语，供你直接用于技术会议或面试中使用：

⸻

Refined English Explanation:

The garbage collection process in containerd is metadata-driven rather than event-driven. This means that objects such as snapshots or blobs are not deleted immediately upon container stop or deletion.

Instead, containerd maintains an internal object graph and runs a background GC routine that scans metadata to determine whether an object is still referenced. If any lease or parent-child relationship exists, the object is preserved.

Lease objects explicitly track ownership and reference chains. Whenever a container or snapshot is created or removed, the corresponding lease and reference metadata is updated rather than triggering immediate deletion.

Only when an object has no active lease and its reference count drops to zero will it become eligible for GC. This design is intentional—it ensures safety in the face of crash recovery, race conditions, or concurrent module interactions.

It trades immediacy for consistency and robustness, which is critical in long-running container environments.

⸻

加分术语点拨：

表达方式	替代术语
“check if object has parent or children”	check reference graph or reachability
“guarantee no deletion happens by mistake”	ensure deletion only occurs with zero references
“GC will leave that over there”	GC will skip or retain the object


⸻

是否需要我将这段也保存为 Markdown “面试表达句库”？我们也可以继续进入模块 4（系统设计 + 成本优化模拟题），你说。






你的 Code Review 评论写得非常到位，已经包含了：
	•	并发问题（多个 goroutine 异常并行）；
	•	资源泄露（没有 context-aware cancellation）；
	•	缺少 retry / backoff；
	•	缺乏 instrumentation；
	•	以及建议的重构方向（context + mutex + observability）。

现在我帮你把这段优化为一段可以直接用于 GitHub PR 中的 专业英文 Code Review 评论，如下：

⸻

Refined Code Review Comment (可复制提交)

Thanks for the patch. I noticed that this snapshot cleanup logic is being handled via a detached goroutine with a fixed delay.

A few concerns:
- Without context propagation or timeout handling, this goroutine could leak under unexpected conditions, especially if the parent routine is cancelled.
- If multiple routines enter this path concurrently, we risk executing `cleanupSnapshot(id)` multiple times, leading to race conditions or inconsistent snapshot states.
- There's no backoff or retry strategy for failure scenarios, which may result in silent data inconsistencies.

I'd recommend:
1. Using a context-aware goroutine with timeout and cancellation support.
2. Instrumenting the cleanup operation (e.g., snapshot ID, error, latency).
3. Wrapping the cleanup logic in a mutex or equivalent critical section to ensure safe concurrency.

Let me know what you think!


⸻

如果你想把这个 review 结构作为你自己未来的 review checklist 模板，我可以再为你总结一份 Code Review Checklist（并发 & 清理路径版）。
现在我们可以进入模块 3（英文表达练习）或模块 4（系统设计 + 成本分析）。你想继续哪个？



var cleanupMu sync.Mutex  // should be defined at package level or per snapshot tracker

func maybeCleanupSnapshot(ctx context.Context, id string) {
    if !snapshotExists(id) {
        return
    }

    go func(ctx context.Context, snapshotID string) {
        // Add timeout to prevent long-running goroutines
        cleanupCtx, cancel := context.WithTimeout(ctx, 30*time.Second)
        defer cancel()

        // Delay before cleanup
        select {
        case <-time.After(10 * time.Second):
        case <-cleanupCtx.Done():
            log.G(ctx).Warnf("Snapshot cleanup for %s cancelled before execution", snapshotID)
            return
        }

        cleanupMu.Lock()
        defer cleanupMu.Unlock()

        if err := cleanupSnapshot(snapshotID); err != nil {
            log.G(ctx).WithError(err).Errorf("Failed to clean up snapshot: %s", snapshotID)
            metrics.SnapshotCleanupFailures.Inc() // hypothetical metric hook
        } else {
            metrics.SnapshotCleanupSuccesses.Inc()
            log.G(ctx).Infof("Snapshot %s successfully cleaned up", snapshotID)
        }
    }(ctx, id)
}